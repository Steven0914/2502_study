{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 딥러닝을 가능케하는 autograd",
   "id": "6765917e266726a6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-06T18:30:32.555584Z",
     "start_time": "2025-09-06T18:30:31.308491Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "# requires_grad의 기본값은 False\n",
    "# 안의 값은 실수여야함 -> 미분은 실수에 대해서만 가능하니까\n",
    "print(x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T18:33:27.569616Z",
     "start_time": "2025-09-06T18:33:27.563346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.])\n",
    "# requires_grad의 기본값은 False\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "\n",
    "x.requires_grad = True\n",
    "print(x)"
   ],
   "id": "c05012722497bdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "False\n",
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T18:44:24.918105Z",
     "start_time": "2025-09-06T18:44:24.853757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "print(y)\n",
    "# grad_fn로 PowBackward0가 붙어있는걸 확인할 수 있다.\n",
    "# grad_fn은 이 requires_grad가 True인 변수에 대해 어떤 연산을 했는지 표시\n",
    "# 실제론 모든 연산이 다 포함되지만, 가장 마지막에 한 연산만 표시함.\n",
    "\n",
    "print(x.grad)\n",
    "y.backward()\n",
    "print(x.grad) # y = x**2를 미분한 값에 1을 대입한 gradient가 담긴다."
   ],
   "id": "d23fddedc46c4698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<PowBackward0>)\n",
      "None\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T07:00:52.341583Z",
     "start_time": "2025-09-07T07:00:52.323544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "print(y)\n",
    "# y.retain_grad() # 이걸 하면 y.grad도 볼 수 있다\n",
    "\n",
    "z = 3*y\n",
    "print(z)\n",
    "# MulBackward0 가 붙어있다!\n",
    "# 마지막으로 한 연산이 곱이였기 때문\n",
    "\n",
    "z.backward()\n",
    "print(x.grad) # chain rule로 알아냄\n",
    "# print(y.grad) # warning! 중간건 안된다\n",
    "# 주석 풀고 실행해보면 y가 리프텐서가 아니라고 뜸(리프텐서가 requires_grad True인거)\n",
    "# 이는 중간 다리역할을 하는 것들의 그래디언트를 저장하면 메모리 소모가 심함.\n",
    "# 위에 retain_grad()를 써주면 유지가 돼서 볼 수 있음. 안쓰면 볼 수 없음."
   ],
   "id": "a233a6dfbb57d299",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<PowBackward0>)\n",
      "tensor([3.], grad_fn=<MulBackward0>)\n",
      "tensor([6.])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T07:03:47.140348Z",
     "start_time": "2025-09-07T07:03:47.119831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "z = 3*y\n",
    "\n",
    "y.backward() # y에서 부터 backward연산을 할 수도 있다.\n",
    "print(x.grad) # chain rule로 알아냄"
   ],
   "id": "aeb19c2e01999438",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T08:01:55.976998Z",
     "start_time": "2025-09-07T08:01:55.951892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 다변수에 대해서도 정상적으로 작동한다.\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = torch.tensor([1.], requires_grad=True)\n",
    "z = 2*x**2 + y**2\n",
    "print(z)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ],
   "id": "194f0aadcd3f53d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.], grad_fn=<AddBackward0>)\n",
      "tensor([4.])\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T08:02:33.397843Z",
     "start_time": "2025-09-07T08:02:33.375784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 하나의 값이 아니라 텐서 형태도 정상적으로 잘된다.\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = torch.sum(x**2) # x1**2 + x2**2 + x3**2\n",
    "y.backward()\n",
    "\n",
    "print(y)\n",
    "print(x.grad) # 스칼라를 벡터로 미분"
   ],
   "id": "da507a7e22ba54c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T10:24:24.068774Z",
     "start_time": "2025-09-07T10:24:24.005291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transfer learning할때 일부 텐서는 변화하지 않게 바꿀 수 있음.\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "x.requires_grad = False\n",
    "# transfer learning 할 때 필요\n",
    "y = x**2\n",
    "print(y)\n",
    "# y.backward() # error!"
   ],
   "id": "f19e5bb2a4853f00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T10:29:25.098360Z",
     "start_time": "2025-09-07T10:29:25.081334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([2.], requires_grad=True)\n",
    "x2 = x.detach()\n",
    "# detach는 값은 그대로이고 requires_grad=False 인 새로운 텐서를 만드는 것\n",
    "print(x)\n",
    "print(x2)\n",
    "y = x**2\n",
    "print(y)\n",
    "y2 = x2**2\n",
    "print(y2)"
   ],
   "id": "4036cc684fb60c21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True)\n",
      "tensor([2.])\n",
      "tensor([4.], grad_fn=<PowBackward0>)\n",
      "tensor([4.])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T10:36:26.233734Z",
     "start_time": "2025-09-07T10:36:26.218006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# detach 사용 용도\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "z = y.detach()\n",
    "# x로 만든 것을 상수로 사용하고 싶은 것.\n",
    "# 중간에 y.requires_grad=False 이런 식으론 불가능\n",
    "# 이것도  transfer learning할때 이미 학습된 모델에서 feature만 떼와서 넣음\n",
    "w = y + z # x**2+1 과 같다\n",
    "\n",
    "w.backward()\n",
    "print(x.grad)"
   ],
   "id": "88a8d6efdc201f1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T10:39:16.259939Z",
     "start_time": "2025-09-07T10:39:16.168105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 많이 쓰이는 torch.no_grad()\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "# chain rule을 위해 계속 grad_fn을 update 하니까\n",
    "# grad_fn 잠시 안 계산하고 싶을 때 사용\n",
    "# 모델 테스트 시에는 불필요하게 메모리 쓸 필요 없기 때문!\n",
    "with torch.no_grad():\n",
    "    y = x**2\n",
    "    print(x.requires_grad) # 이것도 True임 즉 no_grad를 써도 requires_grad는 유지됨\n",
    "    print(y) # with 안에서 계산되는 애는 grad_fn 이 안붙음\n",
    "print(x.requires_grad)\n",
    "# y.backward() # error!\n",
    "\n",
    "y = x**2\n",
    "print(y)\n",
    "\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "x.requires_grad=False\n",
    "y = x**2\n",
    "print(x.requires_grad)\n",
    "print(y)\n",
    "# y.backward() # error!"
   ],
   "id": "b8a843ebda21adae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([1.])\n",
      "True\n",
      "tensor([1.], grad_fn=<PowBackward0>)\n",
      "False\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T11:04:18.497321Z",
     "start_time": "2025-09-07T11:04:17.524853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install torchviz\n",
    "from torchviz import make_dot\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "# make_dot(x)\n",
    "# make_dot(x**2) # (1) 이라고 써있는 것은 shape 을 나타냄\n",
    "# make_dot(x**2+1)\n",
    "# make_dot((x**2+1)**2)\n",
    "\n",
    "y=2*x\n",
    "z=3+x\n",
    "r=y+z\n",
    "make_dot(r)\n",
    "\n",
    "# 참고\n",
    "# AccumulateGrad: x (requires_grad=True인 텐서), 그래디언트 최종 저장소.\n",
    "# AddmmBackward0: nn.Linear (선형 계층), 행렬 곱셈과 덧셈(Wx+b)의 미분.\n",
    "# ConvolutionBackward0: nn.Conv2d (컨볼루션), 컨볼루션 연산의 미분.\n",
    "# ReluBackward0: nn.ReLU (활성화 함수), ReLU 함수의 미분 (0보다 큰 부분만 그래디언트 통과).\n",
    "# SumBackward0 / MeanBackward0: torch.sum / torch.mean (합계/평균), 손실 계산에 사용되며 그래디언트를 모든 원소에 동일하게 전파.\n",
    "# MulBackward0 / AddBackward0: * / + (곱셈/덧셈), 기본 산술 연산의 미분.\n",
    "# PowBackward0: ** (거듭제곱), 거듭제곱 함수의 미분.\n"
   ],
   "id": "5a7daf1a60cb235c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (0.0.3)\r\n",
      "Requirement already satisfied: torch in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torchviz) (2.2.2)\r\n",
      "Requirement already satisfied: graphviz in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torchviz) (0.21)\r\n",
      "Requirement already satisfied: filelock in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torch->torchviz) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torch->torchviz) (4.15.0)\r\n",
      "Requirement already satisfied: sympy in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torch->torchviz) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torch->torchviz) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torch->torchviz) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from torch->torchviz) (2025.9.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from jinja2->torch->torchviz) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hyun-uk/anaconda3/envs/torch0902/lib/python3.12/site-packages (from sympy->torch->torchviz) (1.3.0)\r\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.0 (20241103.1931)\n -->\n<!-- Pages: 1 -->\n<svg width=\"202pt\" height=\"280pt\"\n viewBox=\"0.00 0.00 202.00 279.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 275.75)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-275.75 198,-275.75 198,4 -4,4\"/>\n<!-- 4558069248 -->\n<g id=\"node1\" class=\"node\">\n<title>4558069248</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"124,-32.75 70,-32.75 70,0 124,0 124,-32.75\"/>\n<text text-anchor=\"middle\" x=\"97\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 4561550976 -->\n<g id=\"node2\" class=\"node\">\n<title>4561550976</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-89.5 53,-89.5 53,-68.75 141,-68.75 141,-89.5\"/>\n<text text-anchor=\"middle\" x=\"97\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 4561550976&#45;&gt;4558069248 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4561550976&#45;&gt;4558069248</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97,-68.36C97,-61.89 97,-53.05 97,-44.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-44.55 97,-34.55 93.5,-44.55 100.5,-44.55\"/>\n</g>\n<!-- 4561650928 -->\n<g id=\"node3\" class=\"node\">\n<title>4561650928</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"88,-146.25 0,-146.25 0,-125.5 88,-125.5 88,-146.25\"/>\n<text text-anchor=\"middle\" x=\"44\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 4561650928&#45;&gt;4561550976 -->\n<g id=\"edge1\" class=\"edge\">\n<title>4561650928&#45;&gt;4561550976</title>\n<path fill=\"none\" stroke=\"black\" d=\"M53.48,-125.09C60.79,-117.53 71.09,-106.89 79.84,-97.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"82.11,-100.54 86.55,-90.92 77.08,-95.67 82.11,-100.54\"/>\n</g>\n<!-- 4561650736 -->\n<g id=\"node4\" class=\"node\">\n<title>4561650736</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"147,-203 47,-203 47,-182.25 147,-182.25 147,-203\"/>\n<text text-anchor=\"middle\" x=\"97\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 4561650736&#45;&gt;4561650928 -->\n<g id=\"edge2\" class=\"edge\">\n<title>4561650736&#45;&gt;4561650928</title>\n<path fill=\"none\" stroke=\"black\" d=\"M87.52,-181.84C80.21,-174.28 69.91,-163.64 61.16,-154.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"63.92,-152.42 54.45,-147.67 58.89,-157.29 63.92,-152.42\"/>\n</g>\n<!-- 4561649968 -->\n<g id=\"node6\" class=\"node\">\n<title>4561649968</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"194,-146.25 106,-146.25 106,-125.5 194,-125.5 194,-146.25\"/>\n<text text-anchor=\"middle\" x=\"150\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 4561650736&#45;&gt;4561649968 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4561650736&#45;&gt;4561649968</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.48,-181.84C113.79,-174.28 124.09,-163.64 132.84,-154.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.11,-157.29 139.55,-147.67 130.08,-152.42 135.11,-157.29\"/>\n</g>\n<!-- 4558063648 -->\n<g id=\"node5\" class=\"node\">\n<title>4558063648</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"124,-271.75 70,-271.75 70,-239 124,-239 124,-271.75\"/>\n<text text-anchor=\"middle\" x=\"97\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 4558063648&#45;&gt;4561650736 -->\n<g id=\"edge3\" class=\"edge\">\n<title>4558063648&#45;&gt;4561650736</title>\n<path fill=\"none\" stroke=\"black\" d=\"M97,-238.73C97,-231.35 97,-222.43 97,-214.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-214.66 97,-204.66 93.5,-214.66 100.5,-214.66\"/>\n</g>\n<!-- 4561649968&#45;&gt;4561550976 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4561649968&#45;&gt;4561550976</title>\n<path fill=\"none\" stroke=\"black\" d=\"M140.52,-125.09C133.21,-117.53 122.91,-106.89 114.16,-97.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"116.92,-95.67 107.45,-90.92 111.89,-100.54 116.92,-95.67\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10d7d43e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
